{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BiLSTM POSTagger.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install torchtext=='0.10.0'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qlKaSth8OnZB",
        "outputId": "846bec0b-1d12-4295-d8c1-4944f511f22c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torchtext==0.10.0\n",
            "  Downloading torchtext-0.10.0-cp37-cp37m-manylinux1_x86_64.whl (7.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.6 MB 4.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torchtext==0.10.0) (4.64.0)\n",
            "Collecting torch==1.9.0\n",
            "  Downloading torch-1.9.0-cp37-cp37m-manylinux1_x86_64.whl (831.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 831.4 MB 2.8 kB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchtext==0.10.0) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchtext==0.10.0) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.9.0->torchtext==0.10.0) (4.1.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.10.0) (2022.6.15)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.10.0) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.10.0) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.10.0) (3.0.4)\n",
            "Installing collected packages: torch, torchtext\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.11.0+cu113\n",
            "    Uninstalling torch-1.11.0+cu113:\n",
            "      Successfully uninstalled torch-1.11.0+cu113\n",
            "  Attempting uninstall: torchtext\n",
            "    Found existing installation: torchtext 0.12.0\n",
            "    Uninstalling torchtext-0.12.0:\n",
            "      Successfully uninstalled torchtext-0.12.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchvision 0.12.0+cu113 requires torch==1.11.0, but you have torch 1.9.0 which is incompatible.\n",
            "torchaudio 0.11.0+cu113 requires torch==1.11.0, but you have torch 1.9.0 which is incompatible.\u001b[0m\n",
            "Successfully installed torch-1.9.0 torchtext-0.10.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6l8hg9fs57Q-"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "import torchtext\n",
        "from torchtext.legacy import data\n",
        "from torchtext.legacy import datasets\n",
        "\n",
        "import spacy\n",
        "import numpy as np\n",
        "\n",
        "import time\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "\n",
        "# torch.__version__, torchtext.__version__ # ('1.9.0+cu102', '0.10.0')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SEED = 1234\n",
        "\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True"
      ],
      "metadata": {
        "id": "7lSemhOT7TDq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TEXT = data.Field(lower=True)\n",
        "UD_TAGS = data.Field(unk_token = None)\n",
        "PTB_TAGS = data.Field(unk_token = None)\n",
        "\n",
        "fields = ((\"text\", TEXT), (\"udtags\", UD_TAGS), (\"ptbtags\", PTB_TAGS))\n",
        "train_data, valid_data, test_data = datasets.UDPOS.splits(fields)\n",
        "\n",
        "print(f\"Number of training examples: {len(train_data)}\")\n",
        "print(f\"Number of validation examples: {len(valid_data)}\")\n",
        "print(f\"Number of testing examples: {len(test_data)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CIMwBd5K7TGT",
        "outputId": "12202ae7-cdb7-4d66-b155-0288b1512cda"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "downloading en-ud-v2.zip\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "en-ud-v2.zip: 100%|██████████| 688k/688k [00:00<00:00, 4.70MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "extracting\n",
            "Number of training examples: 12543\n",
            "Number of validation examples: 2002\n",
            "Number of testing examples: 2077\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"{vars(train_data.examples[0])}\\n\\n\")\n",
        "\n",
        "print(f\"TEXT:\\n{vars(train_data.examples[0])['text']}\\n\")\n",
        "print(f\"UDTAGS:\\n{vars(train_data.examples[0])['udtags']}\\n\")\n",
        "print(f\"PTBTAGS:\\n{vars(train_data.examples[0])['ptbtags']}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vF6WuJFv7TIy",
        "outputId": "6e6b45b7-2bcd-4e88-c725-ee7e167af610"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'text': ['al', '-', 'zaman', ':', 'american', 'forces', 'killed', 'shaikh', 'abdullah', 'al', '-', 'ani', ',', 'the', 'preacher', 'at', 'the', 'mosque', 'in', 'the', 'town', 'of', 'qaim', ',', 'near', 'the', 'syrian', 'border', '.'], 'udtags': ['PROPN', 'PUNCT', 'PROPN', 'PUNCT', 'ADJ', 'NOUN', 'VERB', 'PROPN', 'PROPN', 'PROPN', 'PUNCT', 'PROPN', 'PUNCT', 'DET', 'NOUN', 'ADP', 'DET', 'NOUN', 'ADP', 'DET', 'NOUN', 'ADP', 'PROPN', 'PUNCT', 'ADP', 'DET', 'ADJ', 'NOUN', 'PUNCT'], 'ptbtags': ['NNP', 'HYPH', 'NNP', ':', 'JJ', 'NNS', 'VBD', 'NNP', 'NNP', 'NNP', 'HYPH', 'NNP', ',', 'DT', 'NN', 'IN', 'DT', 'NN', 'IN', 'DT', 'NN', 'IN', 'NNP', ',', 'IN', 'DT', 'JJ', 'NN', '.']}\n",
            "\n",
            "\n",
            "TEXT:\n",
            "['al', '-', 'zaman', ':', 'american', 'forces', 'killed', 'shaikh', 'abdullah', 'al', '-', 'ani', ',', 'the', 'preacher', 'at', 'the', 'mosque', 'in', 'the', 'town', 'of', 'qaim', ',', 'near', 'the', 'syrian', 'border', '.']\n",
            "\n",
            "UDTAGS:\n",
            "['PROPN', 'PUNCT', 'PROPN', 'PUNCT', 'ADJ', 'NOUN', 'VERB', 'PROPN', 'PROPN', 'PROPN', 'PUNCT', 'PROPN', 'PUNCT', 'DET', 'NOUN', 'ADP', 'DET', 'NOUN', 'ADP', 'DET', 'NOUN', 'ADP', 'PROPN', 'PUNCT', 'ADP', 'DET', 'ADJ', 'NOUN', 'PUNCT']\n",
            "\n",
            "PTBTAGS:\n",
            "['NNP', 'HYPH', 'NNP', ':', 'JJ', 'NNS', 'VBD', 'NNP', 'NNP', 'NNP', 'HYPH', 'NNP', ',', 'DT', 'NN', 'IN', 'DT', 'NN', 'IN', 'DT', 'NN', 'IN', 'NNP', ',', 'IN', 'DT', 'JJ', 'NN', '.']\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MIN_FREQ = 2\n",
        "\n",
        "# TEXT.build_vocab(\n",
        "#     train_data, min_freq=MIN_FREQ, vectors=\"glove.6B.100d\", unk_init=torch.Tensor.normal_\n",
        "# )\n",
        "TEXT.build_vocab(\n",
        "    train_data, min_freq=MIN_FREQ\n",
        ")\n",
        "\n",
        "UD_TAGS.build_vocab(\n",
        "    train_data\n",
        ")\n",
        "\n",
        "PTB_TAGS.build_vocab(\n",
        "    train_data\n",
        ")\n",
        "\n",
        "print(f\"Unique tokens in TEXT vocabulary: {len(TEXT.vocab)}\")\n",
        "print(f\"Unique tokens in UD_TAG vocabulary: {len(UD_TAGS.vocab)}\")\n",
        "print(f\"Unique tokens in PTB_TAG vocabulary: {len(PTB_TAGS.vocab)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jre5IrPT7TLT",
        "outputId": "fb9f3628-83a4-4ab6-edc6-5dba8ba7da95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique tokens in TEXT vocabulary: 8866\n",
            "Unique tokens in UD_TAG vocabulary: 18\n",
            "Unique tokens in PTB_TAG vocabulary: 51\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"{TEXT.vocab.freqs.most_common(10)}\\n\")\n",
        "print(f\"{UD_TAGS.vocab.freqs.most_common(10)}\\n\")\n",
        "print(f\"{PTB_TAGS.vocab.freqs.most_common(10)}\\n\")"
      ],
      "metadata": {
        "id": "6Br74mcG7T3T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28c45143-0bc0-49cd-e6b2-b1f3ff30e6e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('the', 9076), ('.', 8640), (',', 7021), ('to', 5137), ('and', 5002), ('a', 3782), ('of', 3622), ('i', 3379), ('in', 3112), ('is', 2239)]\n",
            "\n",
            "[('NOUN', 34781), ('PUNCT', 23679), ('VERB', 23081), ('PRON', 18577), ('ADP', 17638), ('DET', 16285), ('PROPN', 12946), ('ADJ', 12477), ('AUX', 12343), ('ADV', 10548)]\n",
            "\n",
            "[('NN', 26915), ('IN', 20724), ('DT', 16817), ('NNP', 12449), ('PRP', 12193), ('JJ', 11591), ('RB', 10831), ('.', 10317), ('VB', 9476), ('NNS', 8438)]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"{UD_TAGS.vocab.itos}\\n\\n\")\n",
        "print(f\"{PTB_TAGS.vocab.itos}\\n\\n\")"
      ],
      "metadata": {
        "id": "coN3pvKU7T56",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "685d16bb-04a5-48a8-ae8d-2e08d47cf575"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['<pad>', 'NOUN', 'PUNCT', 'VERB', 'PRON', 'ADP', 'DET', 'PROPN', 'ADJ', 'AUX', 'ADV', 'CCONJ', 'PART', 'NUM', 'SCONJ', 'X', 'INTJ', 'SYM']\n",
            "\n",
            "\n",
            "['<pad>', 'NN', 'IN', 'DT', 'NNP', 'PRP', 'JJ', 'RB', '.', 'VB', 'NNS', ',', 'CC', 'VBD', 'VBP', 'VBZ', 'CD', 'VBN', 'VBG', 'MD', 'TO', 'PRP$', '-RRB-', '-LRB-', 'WDT', 'WRB', ':', '``', \"''\", 'WP', 'RP', 'UH', 'POS', 'HYPH', 'JJR', 'NNPS', 'JJS', 'EX', 'NFP', 'GW', 'ADD', 'RBR', '$', 'PDT', 'RBS', 'SYM', 'LS', 'FW', 'AFX', 'WP$', 'XX']\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tag_percentage(tag_counts):\n",
        "    total_count = sum([count for tag, count in tag_counts])\n",
        "    tag_counts_percentages = [\n",
        "        (tag, count, count/total_count) for tag, count in tag_counts\n",
        "    ]\n",
        "    return tag_counts_percentages"
      ],
      "metadata": {
        "id": "z8J2Jl5i7T8b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Tag\\t\\tCount\\t\\tPercentage\\n----------------------------------------\")\n",
        "for tag, count, percent in tag_percentage(UD_TAGS.vocab.freqs.most_common()):\n",
        "    print(f\"{tag}\\t\\t{count}\\t\\t{percent*100:4.1f}%\")"
      ],
      "metadata": {
        "id": "tsr1SCH-7UBT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0878ef5-b9f5-466d-9f6d-59cd541aac87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tag\t\tCount\t\tPercentage\n",
            "----------------------------------------\n",
            "NOUN\t\t34781\t\t17.0%\n",
            "PUNCT\t\t23679\t\t11.6%\n",
            "VERB\t\t23081\t\t11.3%\n",
            "PRON\t\t18577\t\t 9.1%\n",
            "ADP\t\t17638\t\t 8.6%\n",
            "DET\t\t16285\t\t 8.0%\n",
            "PROPN\t\t12946\t\t 6.3%\n",
            "ADJ\t\t12477\t\t 6.1%\n",
            "AUX\t\t12343\t\t 6.0%\n",
            "ADV\t\t10548\t\t 5.2%\n",
            "CCONJ\t\t6707\t\t 3.3%\n",
            "PART\t\t5567\t\t 2.7%\n",
            "NUM\t\t3999\t\t 2.0%\n",
            "SCONJ\t\t3843\t\t 1.9%\n",
            "X\t\t847\t\t 0.4%\n",
            "INTJ\t\t688\t\t 0.3%\n",
            "SYM\t\t599\t\t 0.3%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Tag\\t\\tCount\\t\\tPercentage\\n----------------------------------------\")\n",
        "\n",
        "for tag, count, percent in tag_percentage(PTB_TAGS.vocab.freqs.most_common()):\n",
        "    print(f\"{tag}\\t\\t{count}\\t\\t{percent*100:4.1f}%\")"
      ],
      "metadata": {
        "id": "J-rP0bAI7UDz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd7bcb9c-1165-4bed-b5f8-54b7a28bd36e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tag\t\tCount\t\tPercentage\n",
            "----------------------------------------\n",
            "NN\t\t26915\t\t13.2%\n",
            "IN\t\t20724\t\t10.1%\n",
            "DT\t\t16817\t\t 8.2%\n",
            "NNP\t\t12449\t\t 6.1%\n",
            "PRP\t\t12193\t\t 6.0%\n",
            "JJ\t\t11591\t\t 5.7%\n",
            "RB\t\t10831\t\t 5.3%\n",
            ".\t\t10317\t\t 5.0%\n",
            "VB\t\t9476\t\t 4.6%\n",
            "NNS\t\t8438\t\t 4.1%\n",
            ",\t\t8062\t\t 3.9%\n",
            "CC\t\t6706\t\t 3.3%\n",
            "VBD\t\t5402\t\t 2.6%\n",
            "VBP\t\t5374\t\t 2.6%\n",
            "VBZ\t\t4578\t\t 2.2%\n",
            "CD\t\t3998\t\t 2.0%\n",
            "VBN\t\t3967\t\t 1.9%\n",
            "VBG\t\t3330\t\t 1.6%\n",
            "MD\t\t3294\t\t 1.6%\n",
            "TO\t\t3286\t\t 1.6%\n",
            "PRP$\t\t3068\t\t 1.5%\n",
            "-RRB-\t\t1008\t\t 0.5%\n",
            "-LRB-\t\t973\t\t 0.5%\n",
            "WDT\t\t948\t\t 0.5%\n",
            "WRB\t\t869\t\t 0.4%\n",
            ":\t\t866\t\t 0.4%\n",
            "``\t\t813\t\t 0.4%\n",
            "''\t\t785\t\t 0.4%\n",
            "WP\t\t760\t\t 0.4%\n",
            "RP\t\t755\t\t 0.4%\n",
            "UH\t\t689\t\t 0.3%\n",
            "POS\t\t684\t\t 0.3%\n",
            "HYPH\t\t664\t\t 0.3%\n",
            "JJR\t\t503\t\t 0.2%\n",
            "NNPS\t\t498\t\t 0.2%\n",
            "JJS\t\t383\t\t 0.2%\n",
            "EX\t\t359\t\t 0.2%\n",
            "NFP\t\t338\t\t 0.2%\n",
            "GW\t\t294\t\t 0.1%\n",
            "ADD\t\t292\t\t 0.1%\n",
            "RBR\t\t276\t\t 0.1%\n",
            "$\t\t258\t\t 0.1%\n",
            "PDT\t\t175\t\t 0.1%\n",
            "RBS\t\t169\t\t 0.1%\n",
            "SYM\t\t156\t\t 0.1%\n",
            "LS\t\t117\t\t 0.1%\n",
            "FW\t\t93\t\t 0.0%\n",
            "AFX\t\t48\t\t 0.0%\n",
            "WP$\t\t15\t\t 0.0%\n",
            "XX\t\t1\t\t 0.0%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 128\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
        "    (train_data, valid_data, test_data), \n",
        "    batch_size = BATCH_SIZE,\n",
        "    device = device)"
      ],
      "metadata": {
        "id": "jxRHR2aK7UGF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BiLSTMPOSTagger(nn.Module):\n",
        "    def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim, \\\n",
        "                 n_layers, bidirectional, dropout, pad_idx):\n",
        "        super().__init__()\n",
        "\n",
        "        self.embedding = nn.Embedding(input_dim, embedding_dim, padding_idx=pad_idx)\n",
        "        self.lstm = nn.LSTM(\n",
        "            embedding_dim, hidden_dim, num_layers=n_layers, bidirectional=bidirectional,\n",
        "            dropout=dropout if n_layers>1 else 0\n",
        "        )\n",
        "        self.fc = nn.Linear(\n",
        "            hidden_dim*2 if bidirectional else hidden_dim,\n",
        "            output_dim\n",
        "        )\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "    \n",
        "\n",
        "    def forward(self, text):\n",
        "        # text: [sent len, batch size]\n",
        "        embedded = self.dropout(self.embedding(text))\n",
        "        # embedded: [sent len, batch size, emb dim]\n",
        "        outputs, (hidden, cell) = self.lstm(embedded)\n",
        "        # outputs: [sent len, batch size, hid dim x n directions]\n",
        "        # hidden, cell: [n layers, n directions, batch size, hid dim]\n",
        "        predictions = self.fc(self.dropout(outputs))\n",
        "        # predictions: [sent len, batch size, output dim]\n",
        "        return predictions\n"
      ],
      "metadata": {
        "id": "duA08YP87UIm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "INPUT_DIM = len(TEXT.vocab)\n",
        "EMBEDDING_DIM = 100\n",
        "HIDDEN_DIM = 128\n",
        "OUTPUT_DIM = len(UD_TAGS.vocab)\n",
        "N_LAYERS = 2\n",
        "BIDIRECTIONAL = True\n",
        "DROPOUT = 0.25\n",
        "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]"
      ],
      "metadata": {
        "id": "io_Af3kvXX34"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = BiLSTMPOSTagger(\n",
        "    INPUT_DIM, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM, \\\n",
        "    N_LAYERS, BIDIRECTIONAL, DROPOUT, PAD_IDX\n",
        ")"
      ],
      "metadata": {
        "id": "iIHU9qthXX6Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def init_weights(m):\n",
        "    for name, param in m.named_parameters():\n",
        "        nn.init.normal_(param.data, mean = 0, std = 0.1)\n",
        "        \n",
        "model.apply(init_weights)"
      ],
      "metadata": {
        "id": "WU5LhFhIXX82",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0145214-cfca-4981-9750-5b0d1157408d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BiLSTMPOSTagger(\n",
              "  (embedding): Embedding(8866, 100, padding_idx=1)\n",
              "  (lstm): LSTM(100, 128, num_layers=2, dropout=0.25, bidirectional=True)\n",
              "  (fc): Linear(in_features=256, out_features=18, bias=True)\n",
              "  (dropout): Dropout(p=0.25, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "metadata": {
        "id": "9Ui0yhBKXX_e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f06e3756-7c41-4f9d-c1fb-2892ce0acc6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The model has 1,522,010 trainable parameters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # initialize the model's embedding layer with pre-trained embedding values loaded earlier\n",
        "# pretrained_embeddings = TEXT.vocab.vectors\n",
        "# print(pretrained_embeddings.shape)\n",
        "\n",
        "# model.embedding.weight.data.copy_(pretrained_embeddings)"
      ],
      "metadata": {
        "id": "HfzK_A7HXYCI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)\n",
        "# print(model.embedding.weight.data)"
      ],
      "metadata": {
        "id": "HNBtaWca7UKs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = optim.Adam(model.parameters())\n",
        "\n",
        "TAG_PAD_IDX = UD_TAGS.vocab.stoi[UD_TAGS.pad_token]\n",
        "criterion = nn.CrossEntropyLoss(ignore_index = TAG_PAD_IDX)\n",
        "\n",
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ],
      "metadata": {
        "id": "3J0uJrQb7UNL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def categorical_accuracy(preds, y, tag_pad_idx):\n",
        "    max_preds = preds.argmax(dim=1, keepdim=True)\n",
        "    non_pad_elements = (y != tag_pad_idx).nonzero()\n",
        "    correct = max_preds[non_pad_elements].squeeze(1).eq(y[non_pad_elements])\n",
        "    return correct.sum() / y[non_pad_elements].shape[0]"
      ],
      "metadata": {
        "id": "joJnwmsz7UPn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, iterator, optimizer, criterion, tag_pad_idx):\n",
        "    epoch_loss, epoch_acc = 0, 0\n",
        "    model.train()\n",
        "\n",
        "    for batch in tqdm(iterator):\n",
        "        text = batch.text\n",
        "        tags = batch.udtags\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        predictions = model(text)\n",
        "        predictions = predictions.view(-1, predictions.shape[-1])\n",
        "        tags = tags.view(-1)\n",
        "        loss = criterion(predictions, tags)\n",
        "        acc = categorical_accuracy(predictions, tags, tag_pad_idx)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc.item()\n",
        "    \n",
        "    return epoch_loss/len(iterator), epoch_acc/len(iterator)"
      ],
      "metadata": {
        "id": "Z9KeEPYsdrhv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, iterator, criterion, tag_pad_idx):\n",
        "    epoch_loss, epoch_acc = 0, 0\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(iterator):\n",
        "            text = batch.text\n",
        "            tags = batch.udtags\n",
        "            predictions = model(text)\n",
        "            predictions = predictions.view(-1, predictions.shape[-1])\n",
        "            tags = tags.view(-1)\n",
        "            loss = criterion(predictions, tags)\n",
        "            acc = categorical_accuracy(predictions, tags, tag_pad_idx)\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "metadata": {
        "id": "dTTYylqv4mby"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "N_EPOCHS = 10\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "    print(f\"Epoch: {epoch} / {N_EPOCHS}\")\n",
        "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion, TAG_PAD_IDX)\n",
        "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion, TAG_PAD_IDX)\n",
        "    print(f\"\\tTrain Loss: {train_loss:.4f}, Train Accuracy: {train_acc*100:.2f}%\")\n",
        "    print(f\"\\tValid Loss: {valid_loss:.4f}, Valid Accuracy: {valid_acc*100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ou4gUS5K4mgJ",
        "outputId": "356e1c39-d71d-4a36-df1c-950d34590e56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0 / 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 98/98 [01:31<00:00,  1.07it/s]\n",
            "100%|██████████| 16/16 [00:01<00:00, 13.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss: 0.5386, Train Accuracy: 83.36%\n",
            "\tValid Loss: 0.5433, Valid Accuracy: 84.15%\n",
            "Epoch: 1 / 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 98/98 [01:30<00:00,  1.08it/s]\n",
            "100%|██████████| 16/16 [00:01<00:00, 13.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss: 0.3155, Train Accuracy: 90.42%\n",
            "\tValid Loss: 0.4569, Valid Accuracy: 86.47%\n",
            "Epoch: 2 / 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 98/98 [01:31<00:00,  1.07it/s]\n",
            "100%|██████████| 16/16 [00:01<00:00, 13.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss: 0.2420, Train Accuracy: 92.51%\n",
            "\tValid Loss: 0.4162, Valid Accuracy: 88.00%\n",
            "Epoch: 3 / 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 98/98 [01:31<00:00,  1.07it/s]\n",
            "100%|██████████| 16/16 [00:01<00:00, 13.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss: 0.2061, Train Accuracy: 93.65%\n",
            "\tValid Loss: 0.3985, Valid Accuracy: 88.29%\n",
            "Epoch: 4 / 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 98/98 [01:31<00:00,  1.07it/s]\n",
            "100%|██████████| 16/16 [00:01<00:00, 13.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss: 0.1807, Train Accuracy: 94.33%\n",
            "\tValid Loss: 0.3875, Valid Accuracy: 88.86%\n",
            "Epoch: 5 / 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 98/98 [01:33<00:00,  1.05it/s]\n",
            "100%|██████████| 16/16 [00:01<00:00, 13.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss: 0.1632, Train Accuracy: 94.87%\n",
            "\tValid Loss: 0.3779, Valid Accuracy: 89.11%\n",
            "Epoch: 6 / 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 98/98 [01:31<00:00,  1.07it/s]\n",
            "100%|██████████| 16/16 [00:01<00:00, 13.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss: 0.1498, Train Accuracy: 95.21%\n",
            "\tValid Loss: 0.3758, Valid Accuracy: 89.26%\n",
            "Epoch: 7 / 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 98/98 [01:31<00:00,  1.07it/s]\n",
            "100%|██████████| 16/16 [00:01<00:00, 13.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss: 0.1361, Train Accuracy: 95.69%\n",
            "\tValid Loss: 0.3744, Valid Accuracy: 89.12%\n",
            "Epoch: 8 / 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 98/98 [01:35<00:00,  1.03it/s]\n",
            "100%|██████████| 16/16 [00:01<00:00, 13.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss: 0.1250, Train Accuracy: 96.04%\n",
            "\tValid Loss: 0.3706, Valid Accuracy: 89.53%\n",
            "Epoch: 9 / 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 98/98 [01:35<00:00,  1.03it/s]\n",
            "100%|██████████| 16/16 [00:01<00:00, 13.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tTrain Loss: 0.1159, Train Accuracy: 96.32%\n",
            "\tValid Loss: 0.3714, Valid Accuracy: 89.05%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = evaluate(model, test_iterator, criterion, TAG_PAD_IDX)\n",
        "print(f\"\\n\\tTest Loss: {test_loss:.4f} \\n\\tTest Accuracy: {test_acc*100:.2f}%\")"
      ],
      "metadata": {
        "id": "wH0ElI1Sdrmm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1073dfe8-ae8d-4543-e68e-153cf7c1278a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 17/17 [00:01<00:00, 14.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\tTest Loss: 0.3817 \n",
            "\tTest Accuracy: 88.44%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tag_sentence(model, device, sentence, text_field, tag_field):\n",
        "    model.eval()\n",
        "\n",
        "    if isinstance(sentence, str):\n",
        "        nlp = spacy.load('en_core_web_sm')\n",
        "        tokens = [token.text for token in nlp(sentence)]\n",
        "    else:\n",
        "        tokens = [token for token in sentence]\n",
        "\n",
        "    if text_field.lower:\n",
        "        tokens = [t.lower() for t in tokens]\n",
        "    \n",
        "    numericalized_tokens = [text_field.vocab.stoi[t] for t in tokens]\n",
        "    unk_idx = text_field.vocab.stoi[text_field.unk_token]\n",
        "    unks = [t for t, n in zip(tokens, numericalized_tokens) if n==unk_idx]\n",
        "    token_tensor = torch.LongTensor(numericalized_tokens)\n",
        "    token_tensor = token_tensor.unsqueeze(-1).to(device)\n",
        "    predictions = model(token_tensor)\n",
        "    top_predictions = predictions.argmax(-1)\n",
        "    predicted_tags = [tag_field.vocab.itos[t.item()] for t in top_predictions]\n",
        "    return tokens, predicted_tags, unks"
      ],
      "metadata": {
        "id": "FBxDR6rSdro-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example_index = 1\n",
        "\n",
        "sentence = vars(train_data.examples[example_index])['text']\n",
        "actual_tags = vars(train_data.examples[example_index])['udtags']\n",
        "\n",
        "print(sentence)\n",
        "print(actual_tags)"
      ],
      "metadata": {
        "id": "W0DyrK2xdrrR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6cb8d5e-e6e8-4eb6-dc8d-239422a6fadd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['[', 'this', 'killing', 'of', 'a', 'respected', 'cleric', 'will', 'be', 'causing', 'us', 'trouble', 'for', 'years', 'to', 'come', '.', ']']\n",
            "['PUNCT', 'DET', 'NOUN', 'ADP', 'DET', 'ADJ', 'NOUN', 'AUX', 'AUX', 'VERB', 'PRON', 'NOUN', 'ADP', 'NOUN', 'PART', 'VERB', 'PUNCT', 'PUNCT']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokens, pred_tags, unks = tag_sentence(\n",
        "    model, device, sentence, TEXT, UD_TAGS\n",
        ")\n",
        "\n",
        "print(unks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ho3_rOldAC-z",
        "outputId": "68d74bb8-ad6f-4431-fdf0-35909b47f07c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['respected', 'cleric']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Pred. Tag\\tActual Tag\\tCorrect?\\tToken\\n-----------------------------------------------------\")\n",
        "for token, pred_tag, actual_tag in zip(tokens, pred_tags, actual_tags):\n",
        "    correct = '✔' if pred_tag == actual_tag else '✘'\n",
        "    print(f\"{pred_tag}\\t\\t{actual_tag}\\t\\t{correct}\\t\\t{token}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CGw4DOfPADDT",
        "outputId": "d660ed8a-88a5-44d9-d348-6a4b24d7beea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pred. Tag\tActual Tag\tCorrect?\tToken\n",
            "-----------------------------------------------------\n",
            "PUNCT\t\tPUNCT\t\t✔\t\t[\n",
            "DET\t\tDET\t\t✔\t\tthis\n",
            "NOUN\t\tNOUN\t\t✔\t\tkilling\n",
            "ADP\t\tADP\t\t✔\t\tof\n",
            "DET\t\tDET\t\t✔\t\ta\n",
            "ADJ\t\tADJ\t\t✔\t\trespected\n",
            "NOUN\t\tNOUN\t\t✔\t\tcleric\n",
            "AUX\t\tAUX\t\t✔\t\twill\n",
            "AUX\t\tAUX\t\t✔\t\tbe\n",
            "VERB\t\tVERB\t\t✔\t\tcausing\n",
            "PRON\t\tPRON\t\t✔\t\tus\n",
            "NOUN\t\tNOUN\t\t✔\t\ttrouble\n",
            "ADP\t\tADP\t\t✔\t\tfor\n",
            "NOUN\t\tNOUN\t\t✔\t\tyears\n",
            "PART\t\tPART\t\t✔\t\tto\n",
            "VERB\t\tVERB\t\t✔\t\tcome\n",
            "PUNCT\t\tPUNCT\t\t✔\t\t.\n",
            "PUNCT\t\tPUNCT\t\t✔\t\t]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "XYio_uNKADHp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = 'The Quick brown Fox jumps Over The lazy Dog.'\n",
        "\n",
        "tokens, tags, unks = tag_sentence(\n",
        "    model, device, sentence, TEXT, UD_TAGS\n",
        ")\n",
        "print(unks)\n",
        "\n",
        "print(\"\\n\\nPred. Tag\\tToken\\n------------------------\")\n",
        "for token, tag in zip(tokens, tags):\n",
        "    print(f\"{tag}\\t\\t{token}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "svl7-voIADLX",
        "outputId": "6ca8a436-8448-4e67-9c69-e32f9b6e63d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['fox']\n",
            "\n",
            "\n",
            "Pred. Tag\tToken\n",
            "------------------------\n",
            "DET\t\tthe\n",
            "ADJ\t\tquick\n",
            "PROPN\t\tbrown\n",
            "PROPN\t\tfox\n",
            "VERB\t\tjumps\n",
            "ADP\t\tover\n",
            "DET\t\tthe\n",
            "ADJ\t\tlazy\n",
            "NOUN\t\tdog\n",
            "PUNCT\t\t.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "KWkS9MkFADOk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "s8OuXmJpAWkY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "References </br>\n",
        "[1] https://github.com/bentrevett/pytorch-pos-tagging/blob/master/1_bilstm.ipynb"
      ],
      "metadata": {
        "id": "pHWPVu6NAZ4Z"
      }
    }
  ]
}